{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq_train.ipynb","provenance":[],"authorship_tag":"ABX9TyO+sRUqsxV5LtyecoIPo3r7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SfyPtPaT8cxo","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kG42-WWS9bCf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"44959d5d-c54f-47ba-ed7a-1c29f9dfbbbf","executionInfo":{"status":"ok","timestamp":1589808438966,"user_tz":-480,"elapsed":106305,"user":{"displayName":"Crise Zhaopp","photoUrl":"","userId":"18306759907168652538"}}},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YLHjMa77_GYW","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Hashing\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkpqZQ2G889X","colab_type":"code","colab":{}},"source":["import warnings \n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cn1zeqQ19Mz5","colab_type":"code","colab":{}},"source":["import os, sys\n","sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks/text-generator\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e824WlzrAXP-","colab_type":"code","colab":{}},"source":["from utils.data_loader import load_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXFwlHYpAfNv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"7b45d960-956f-4ea6-ec6e-e3c6af44daf6","executionInfo":{"status":"ok","timestamp":1589809212024,"user_tz":-480,"elapsed":1739,"user":{"displayName":"Crise Zhaopp","photoUrl":"","userId":"18306759907168652538"}}},"source":["from utils.data_loader import load_test_dataset"],"execution_count":11,"outputs":[{"output_type":"stream","text":["root path: /content/gdrive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3DTPLH8UIgn2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6c9ba80f-5ab3-44bf-8e45-58ce6dccd5d9","executionInfo":{"status":"ok","timestamp":1589811239611,"user_tz":-480,"elapsed":1086,"user":{"displayName":"Crise Zhaopp","photoUrl":"","userId":"18306759907168652538"}}},"source":["from utils.config import embedding_matrix_path\n","embedding_matrix_path"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/My Drive/Colab Notebooks/Hashing/gen_data/embedding_matrix'"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"VvSRWxPkIsdf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"outputId":"d4a85101-1a5e-4d4d-b2cc-4eb7bc328500","executionInfo":{"status":"ok","timestamp":1589811684767,"user_tz":-480,"elapsed":1419,"user":{"displayName":"Crise Zhaopp","photoUrl":"","userId":"18306759907168652538"}}},"source":["from utils.wv_loader import load_embedding_matrix\n","load_embedding_matrix()"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 5.78204274e-01,  6.03120551e-02,  3.60607475e-01, ...,\n","        -3.83604765e-01, -2.35126719e-01, -3.39127541e-01],\n","       [ 2.48232469e-01, -1.09330297e-01, -1.07853085e-01, ...,\n","        -4.05686855e-01, -3.84583443e-01,  8.72177184e-01],\n","       [-2.61794060e-01,  1.58479378e-01, -3.25242400e-01, ...,\n","        -1.04319692e+00, -3.70189011e-01, -6.24906011e-02],\n","       ...,\n","       [ 3.13954473e-01,  6.27483010e-01,  8.70058371e-04, ...,\n","        -6.59883201e-01,  1.04633875e-01,  5.38641512e-02],\n","       [-3.03027540e-01, -6.11446559e-01, -1.08515084e+00, ...,\n","         1.52157664e-01,  3.57411057e-01, -8.81655991e-01],\n","       [ 3.11857313e-01, -5.35719246e-02, -3.20000172e-01, ...,\n","        -1.04822442e-01,  1.92798018e-01, -4.42412287e-01]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"n2j5WvCC9U2p","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from utils.data_loader import load_dataset, preprocess_sentence, load_test_dataset\n","from utils.wv_loader import load_embedding_matrix, load_vocab\n","from utils.config import *\n","from gensim.models.word2vec import LineSentence, Word2Vec\n","import tensorflow as tf\n","# from utils.plot_utils import plot_attention\n","from tqdm import tqdm\n","import time\n","from seq2seq.batcher import train_batch_generator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Llt7zlV6ERKS","colab_type":"code","colab":{}},"source":["vocab_path = \"./gen_data/vocab.txt\"\n","vocab, reverse_vocab=load_vocab(vocab_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V0TXNv5wNw9u","colab_type":"code","colab":{}},"source":["train_X, train_Y, test_X = load_dataset()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Gpl8a75E0Cz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"e38d30c7-f36e-4a5c-f4f2-794b6cd8f2a9","executionInfo":{"status":"ok","timestamp":1589810594370,"user_tz":-480,"elapsed":3117,"user":{"displayName":"Crise Zhaopp","photoUrl":"","userId":"18306759907168652538"}}},"source":["from utils.wv_loader import get_embedding_matrix\n","wv_model_path = \"./gen_data/word2vec.model\"\n","embedding_matrix = get_embedding_matrix(wv_model_path)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["2020-05-18 14:03:11,689 : INFO : loading Word2Vec object from ./gen_data/word2vec.model\n","2020-05-18 14:03:13,649 : INFO : loading wv recursively from ./gen_data/word2vec.model.wv.* with mmap=None\n","2020-05-18 14:03:13,650 : INFO : setting ignored attribute vectors_norm to None\n","2020-05-18 14:03:13,651 : INFO : loading vocabulary recursively from ./gen_data/word2vec.model.vocabulary.* with mmap=None\n","2020-05-18 14:03:13,656 : INFO : loading trainables recursively from ./gen_data/word2vec.model.trainables.* with mmap=None\n","2020-05-18 14:03:13,658 : INFO : setting ignored attribute cum_table to None\n","2020-05-18 14:03:13,659 : INFO : loaded ./gen_data/word2vec.model\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"34MGu07oKLIO","colab_type":"code","colab":{}},"source":["np.save(\"./gen_data/embedding_matrix.npy\", embedding_matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oi8tZzgQGftC","colab_type":"code","colab":{}},"source":["units = 1024"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0st_BuJg_gfs","colab_type":"code","colab":{}},"source":["params = {}\n","params[\"vocab_size\"] = len(vocab)\n","params[\"embed_size\"] = 300\n","params[\"enc_units\"] = units\n","params[\"attn_units\"] = units\n","params[\"dec_units\"] = units\n","params[\"batch_size\"] = 64\n","params[\"epochs\"] = 5\n","params[\"max_enc_len\"] = 200\n","params[\"max_dec_len\"] = 41"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2qbiA7yfOUID","colab_type":"code","colab":{}},"source":["steps_per_epoch = len(train_X) // params[\"batch_size\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrmM6AucObu3","colab_type":"code","colab":{}},"source":["dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y)).shuffle(params[\"batch_size\"])\n","dataset = dataset.batch(params[\"batch_size\"], drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKyfBcBARn_G","colab_type":"code","colab":{}},"source":["from seq2seq.layers import Encoder, BahdanauAttention, Decoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHY5_itfRvFv","colab_type":"code","colab":{}},"source":["encoder = Encoder(params[\"vocab_size\"], params[\"embed_size\"], embedding_matrix, params[\"enc_units\"], params[\"batch_size\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTVyaFjOR-gh","colab_type":"code","colab":{}},"source":["enc_hidden = encoder.initialize_hidden_state()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qYHANqMbS-J0","colab_type":"code","colab":{}},"source":["example_input_batch = tf.ones(shape=(params[\"batch_size\"], params[\"max_enc_len\"]), dtype=tf.int32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbkIZTOGSPwa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"2c62c54a-0d5d-4116-efe3-fef11f00178d","executionInfo":{"status":"ok","timestamp":1589814053022,"user_tz":-480,"elapsed":3893,"user":{"displayName":"Crise Zhaopp","photoUrl":"","userId":"18306759907168652538"}}},"source":["sample_output, sample_hidden = encoder(example_input_batch, enc_hidden)\n","sample_output.shape\n","sample_hidden.shape"],"execution_count":82,"outputs":[{"output_type":"stream","text":["(64, 200, 300)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 1024])"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"Jhg2iXydTXhf","colab_type":"code","colab":{}},"source":["decoder = Decoder(params[\"vocab_size\"], params[\"embed_size\"], embedding_matrix, params[\"enc_units\"], params[\"batch_size\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLLvz66KTk-R","colab_type":"code","colab":{}},"source":["sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)), sample_hidden, sample_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uzGBIMR8UHJA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b038704a-ab50-409a-f7f7-7fc30e55f03e","executionInfo":{"status":"ok","timestamp":1589814265880,"user_tz":-480,"elapsed":1109,"user":{"displayName":"Crise Zhaopp","photoUrl":"","userId":"18306759907168652538"}}},"source":["sample_decoder_output.shape"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 32909])"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"4GnsyEL-EKfC","colab_type":"code","colab":{}},"source":["# from seq2seq.models import Seq2Seq"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ifdO30hHJkB","colab_type":"code","colab":{}},"source":["# model = Seq2Seq(params)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPp7x3g8HObi","colab_type":"code","colab":{}},"source":["checkpoint_dir = \"./gen_data/checkpoints/training_checkpoints_mask_loss_dim300_seq\"\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lo_WUODdNZag","colab_type":"code","colab":{}},"source":["ckpt = tf.train.Checkpoint(Seq2Seq=model)\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ijSGcEbqNdft","colab_type":"code","colab":{}},"source":["## 训练"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-dadaUINiGV","colab_type":"code","colab":{}},"source":["optimizer = tf.keras.optimizers.Adam(name='Adam',learning_rate=0.001)\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","\n","pad_index=vocab['<PAD>']\n","nuk_index=vocab['<UNK>']\n","\n","def loss_function(real, pred):\n","    pad_mask = tf.math.equal(real, pad_index)\n","    nuk_mask = tf.math.equal(real, nuk_index)\n","    mask = tf.math.logical_not(tf.math.logical_or(pad_mask,nuk_mask))\n","    \n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhMWeiS-Nj2U","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","    loss = 0\n","    \n","    with tf.GradientTape() as tape:\n","        # 1. 构建encoder\n","        enc_output, enc_hidden = encoder(inp, enc_hidden)\n","        # 2. 复制\n","        dec_hidden = enc_hidden\n","        # 3. <START> * BATCH_SIZE \n","        dec_input = tf.expand_dims([vocab['<START>']] * params[\"batch_size\"], 1)\n","        \n","        # Teacher forcing - feeding the target as the next input\n","        for t in range(1, targ.shape[1]):\n","            # decoder(x, hidden, enc_output)\n","            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","            \n","            loss += loss_function(targ[:, t], predictions)\n","\n","            # using teacher forcing\n","            dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","        batch_loss = (loss / int(targ.shape[1]))\n","\n","        variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","        gradients = tape.gradient(loss, variables)\n","\n","        optimizer.apply_gradients(zip(gradients, variables))\n","\n","        return batch_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCH-_LiJNmkm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"outputId":"cf0fc98d-8f2d-4de3-9adb-fafbe8338fce"},"source":["epochs = params[\"epochs\"]\n","# 如果检查点存在，则恢复最新的检查点。\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print ('Latest checkpoint restored!!')\n","    \n","for epoch in range(epochs):\n","    start = time.time()\n","    total_loss = 0\n","    enc_hidden = encoder.initialize_hidden_state()\n","\n","    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","        batch_loss = train_step(inp, targ, enc_hidden)\n","        total_loss += batch_loss\n","\n","        if batch % 1 == 0:\n","            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                         batch,\n","                                                         batch_loss.numpy()))\n","    # saving (checkpoint) the model every 2 epochs\n","    if (epoch + 1) % 2 == 0:\n","        ckpt_save_path = ckpt_manager.save()\n","        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                             ckpt_save_path))\n","\n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(64, 260, 300)\n","(64, 260, 300)\n","Epoch 1 Batch 0 Loss 5.7895\n","Epoch 1 Batch 1 Loss 5.0485\n","Epoch 1 Batch 2 Loss 4.6711\n","Epoch 1 Batch 3 Loss 4.4872\n","Epoch 1 Batch 4 Loss 2.9991\n","Epoch 1 Batch 5 Loss 2.8944\n","Epoch 1 Batch 6 Loss 2.2248\n","Epoch 1 Batch 7 Loss 2.3178\n","Epoch 1 Batch 8 Loss 2.5467\n","Epoch 1 Batch 9 Loss 3.2641\n","Epoch 1 Batch 10 Loss 3.4364\n","Epoch 1 Batch 11 Loss 2.9485\n","Epoch 1 Batch 12 Loss 2.7538\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F9xMHWnyNq2l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}