{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append(\"/home/lcz/lenlp/text-generation/py_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置GPU使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root path: /home/lcz/lenlp/text-generation\n"
     ]
    }
   ],
   "source": [
    "from utils.data_loader import load_dataset, load_test_dataset\n",
    "from utils.linux_config import embedding_matrix_path\n",
    "from utils.wv_loader import load_embedding_matrix, load_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = load_embedding_matrix(\"./../data/embedding_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = \"./../data/vocab.txt\"\n",
    "vocab, reverse_vocab = load_vocab(vocab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 1024\n",
    "params = {}\n",
    "params[\"vocab_size\"] = len(vocab)\n",
    "params[\"embed_size\"] = 300\n",
    "params[\"enc_units\"] = units\n",
    "params[\"attn_units\"] = units\n",
    "params[\"dec_units\"] = units\n",
    "params[\"batch_size\"] = 64\n",
    "params[\"epochs\"] = 2\n",
    "params[\"max_enc_len\"] = 200\n",
    "params[\"max_dec_len\"] = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "steps_per_epoch = len(train_X) // params[\"batch_size\"]\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y)).shuffle(params[\"batch_size\"])\n",
    "dataset = dataset.batch(params[\"batch_size\"], drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root path: /home/lcz/lenlp/text-generation\n"
     ]
    }
   ],
   "source": [
    "from seq2seq.layers import Encoder, BahdanauAttention, Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 200, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(params[\"vocab_size\"], params[\"embed_size\"], embedding_matrix, params[\"enc_units\"], params[\"batch_size\"])\n",
    "enc_hidden = encoder.initialize_hidden_state()\n",
    "example_input_batch = tf.ones(shape=(params[\"batch_size\"], params[\"max_enc_len\"]), dtype=tf.int32)\n",
    "sample_output, sample_hidden = encoder(example_input_batch, enc_hidden)\n",
    "sample_output.shape\n",
    "sample_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 32909])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(params[\"vocab_size\"], params[\"embed_size\"], embedding_matrix, params[\"enc_units\"], params[\"batch_size\"])\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)), sample_hidden, sample_output)\n",
    "sample_decoder_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存点设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(name='Adam',learning_rate=0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "pad_index=vocab['<PAD>']\n",
    "nuk_index=vocab['<UNK>']\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    pad_mask = tf.math.equal(real, pad_index)\n",
    "    nuk_mask = tf.math.equal(real, nuk_index)\n",
    "    mask = tf.math.logical_not(tf.math.logical_or(pad_mask,nuk_mask))\n",
    "    \n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "checkpoint_dir = \"./../data/checkpoints/beam_search_training_checkpoints_mask_loss_dim300_seq\"\n",
    "import os\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. 构建encoder\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        # 2. 复制\n",
    "        dec_hidden = enc_hidden\n",
    "        # 3. <START> * BATCH_SIZE \n",
    "        dec_input = tf.expand_dims([vocab['<START>']] * params[\"batch_size\"], 1)\n",
    "        \n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # decoder(x, hidden, enc_output)\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n",
      "(64, 260, 300)\n",
      "(64, 260, 300)\n",
      "Epoch 1 Step 0 Loss 5.0501\n",
      "Epoch 1 Step 1 Loss 5.7422\n",
      "Epoch 1 Step 2 Loss 5.4559\n",
      "Epoch 1 Step 3 Loss 4.3635\n",
      "Epoch 1 Step 4 Loss 4.4234\n",
      "Epoch 1 Step 5 Loss 3.4175\n",
      "Epoch 1 Step 6 Loss 2.3852\n",
      "Epoch 1 Step 7 Loss 2.0323\n",
      "Epoch 1 Step 8 Loss 2.3369\n",
      "Epoch 1 Step 9 Loss 2.7592\n",
      "Epoch 1 Step 10 Loss 3.6975\n",
      "Epoch 1 Step 11 Loss 3.2331\n",
      "Epoch 1 Step 12 Loss 2.5499\n",
      "Epoch 1 Step 13 Loss 3.0730\n",
      "Epoch 1 Step 14 Loss 3.4795\n",
      "Epoch 1 Step 15 Loss 3.6937\n",
      "Epoch 1 Step 16 Loss 2.5997\n",
      "Epoch 1 Step 17 Loss 1.8833\n",
      "Epoch 1 Step 18 Loss 1.8907\n",
      "Epoch 1 Step 19 Loss 1.6549\n",
      "Epoch 1 Step 20 Loss 2.1969\n",
      "Epoch 1 Step 21 Loss 2.3029\n",
      "Epoch 1 Step 22 Loss 2.4705\n",
      "Epoch 1 Step 23 Loss 2.7176\n",
      "Epoch 1 Step 24 Loss 2.5495\n",
      "Epoch 1 Step 25 Loss 2.3808\n",
      "Epoch 1 Step 26 Loss 3.4386\n",
      "Epoch 1 Step 27 Loss 3.0722\n",
      "Epoch 1 Step 28 Loss 3.4121\n",
      "Epoch 1 Step 29 Loss 3.0982\n",
      "Epoch 1 Step 30 Loss 2.7119\n",
      "Epoch 1 Step 31 Loss 2.6307\n",
      "Epoch 1 Step 32 Loss 2.7875\n",
      "Epoch 1 Step 33 Loss 2.3432\n",
      "Epoch 1 Step 34 Loss 2.6013\n",
      "Epoch 1 Step 35 Loss 3.0276\n",
      "Epoch 1 Step 36 Loss 3.0720\n",
      "Epoch 1 Step 37 Loss 3.1297\n",
      "Epoch 1 Step 38 Loss 3.1528\n",
      "Epoch 1 Step 39 Loss 3.2466\n",
      "Epoch 1 Step 40 Loss 3.3595\n",
      "Epoch 1 Step 41 Loss 2.5820\n",
      "Epoch 1 Step 42 Loss 3.0730\n",
      "Epoch 1 Step 43 Loss 3.2449\n",
      "Epoch 1 Step 44 Loss 2.5235\n",
      "Epoch 1 Step 45 Loss 2.7780\n",
      "Epoch 1 Step 46 Loss 2.6731\n",
      "Epoch 1 Step 47 Loss 2.0722\n",
      "Epoch 1 Step 48 Loss 2.8308\n",
      "Epoch 1 Step 49 Loss 3.6808\n",
      "Epoch 1 Step 50 Loss 3.3546\n",
      "Epoch 1 Step 51 Loss 3.0741\n",
      "Epoch 1 Step 52 Loss 3.2227\n",
      "Epoch 1 Step 53 Loss 3.3065\n",
      "Epoch 1 Step 54 Loss 3.1525\n",
      "Epoch 1 Step 55 Loss 1.9576\n",
      "Epoch 1 Step 56 Loss 2.3276\n",
      "Epoch 1 Step 57 Loss 3.1278\n",
      "Epoch 1 Step 58 Loss 2.5930\n",
      "Epoch 1 Step 59 Loss 2.7657\n",
      "Epoch 1 Step 60 Loss 2.9661\n",
      "Epoch 1 Step 61 Loss 2.3243\n",
      "Epoch 1 Step 62 Loss 2.3996\n",
      "Epoch 1 Step 63 Loss 2.1360\n",
      "Epoch 1 Step 64 Loss 2.3307\n",
      "Epoch 1 Step 65 Loss 2.7209\n",
      "Epoch 1 Step 66 Loss 2.6748\n",
      "Epoch 1 Step 67 Loss 3.5661\n",
      "Epoch 1 Step 68 Loss 2.8376\n",
      "Epoch 1 Step 69 Loss 2.6912\n",
      "Epoch 1 Step 70 Loss 2.2355\n",
      "Epoch 1 Step 71 Loss 2.9040\n",
      "Epoch 1 Step 72 Loss 2.8826\n",
      "Epoch 1 Step 73 Loss 3.0341\n",
      "Epoch 1 Step 74 Loss 2.8073\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = params[\"epochs\"]\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir)):\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    print ('Latest checkpoint restored!!')\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            print('Epoch {} Step {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             checkpoint_prefix))\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypothesis:\n",
    "    \"\"\" Class designed to hold hypothesises throughout the beamSearch decoding \"\"\"\n",
    "\n",
    "    def __init__(self, tokens, log_probs, hidden, attn_dists):\n",
    "        self.tokens = tokens  # list of all the tokens from time 0 to the current time step t\n",
    "        self.log_probs = log_probs  # list of the log probabilities of the tokens of the tokens\n",
    "        self.hidden = hidden  # decoder hidden state after the last token decoding\n",
    "        self.attn_dists = attn_dists  # attention dists of all the tokens\n",
    "        self.abstract = \"\"\n",
    "\n",
    "    def extend(self, token, log_prob, hidden, attn_dist):\n",
    "        \"\"\"Method to extend the current hypothesis by adding the next decoded token and all the informations associated with it\"\"\"\n",
    "        return Hypothesis(tokens=self.tokens + [token],  # we add the decoded token\n",
    "                          log_probs=self.log_probs + [log_prob],  # we add the log prob of the decoded token\n",
    "                          hidden=hidden,  # we update the state\n",
    "                          attn_dists=self.attn_dists + [attn_dist])\n",
    "\n",
    "    @property\n",
    "    def latest_token(self):\n",
    "        return self.tokens[-1]\n",
    "\n",
    "    @property\n",
    "    def tot_log_prob(self):\n",
    "        return sum(self.log_probs)\n",
    "\n",
    "    @property\n",
    "    def avg_log_prob(self):\n",
    "        return self.tot_log_prob / len(self.tokens)\n",
    "\n",
    "\n",
    "def beam_decode(model, batch, vocab, params):\n",
    "    # 初始化mask\n",
    "    start_index = vocab.word_to_id(vocab.START_DECODING)\n",
    "    stop_index = vocab.word_to_id(vocab.STOP_DECODING)\n",
    "    unk_index = vocab.word_to_id(vocab.UNKNOWN_TOKEN)\n",
    "\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    # 单步decoder\n",
    "    def decoder_onestep(enc_output, dec_input, dec_hidden, enc_extended_inp, batch_oov_len):\n",
    "        # 单个时间步 运行\n",
    "        # dec_input, dec_hidden, enc_output, enc_extended_inp, batch_oov_len\n",
    "        final_preds, dec_hidden, context_vector, attention_weights, p_gens = model.call_decoder_onestep(dec_input,\n",
    "                                                                                                        dec_hidden,\n",
    "                                                                                                        enc_output,\n",
    "                                                                                                        enc_extended_inp,\n",
    "                                                                                                        batch_oov_len)\n",
    "        # 拿到top k个index 和 概率\n",
    "        top_k_probs, top_k_ids = tf.nn.top_k(tf.squeeze(final_preds), k=params[\"beam_size\"] * 2)\n",
    "        # 计算log概率\n",
    "        top_k_log_probs = tf.math.log(top_k_probs)\n",
    "\n",
    "        results = {\n",
    "            # 'final_dists': preds,\n",
    "            \"last_context_vector\": context_vector,\n",
    "            \"dec_hidden\": dec_hidden,\n",
    "            \"attention_weights\": attention_weights,\n",
    "            \"top_k_ids\": top_k_ids,\n",
    "            \"top_k_log_probs\": top_k_log_probs,\n",
    "            \"p_gen\": p_gens}\n",
    "\n",
    "        # 返回需要保存的中间结果和概率\n",
    "        return results\n",
    "\n",
    "    # 测试数据的输入\n",
    "    enc_input = batch[0][\"enc_input\"]\n",
    "\n",
    "    # 计算第encoder的输出\n",
    "    enc_output, enc_hidden = model.call_encoder(enc_input)\n",
    "\n",
    "    # 初始化batch size个 假设对象\n",
    "    hyps = [Hypothesis(tokens=[start_index],\n",
    "                       log_probs=[0.0],\n",
    "                       hidden=enc_hidden[0],\n",
    "                       attn_dists=[],\n",
    "                       ) for _ in range(batch_size)]\n",
    "    # 初始化结果集\n",
    "    results = []  # list to hold the top beam_size hypothesises\n",
    "    # 遍历步数\n",
    "    steps = 0  # initial step\n",
    "\n",
    "    enc_extended_inp = batch[0][\"extended_enc_input\"]\n",
    "    batch_oov_len = batch[0][\"max_oov_len\"]\n",
    "\n",
    "    # 长度还不够 并且 结果还不够 继续搜索\n",
    "    while steps < params['max_dec_len'] and len(results) < params['beam_size']:\n",
    "        # 获取最新待使用的token\n",
    "        latest_tokens = [h.latest_token for h in hyps]\n",
    "        # 替换掉 oov token unknown token\n",
    "        latest_tokens = [t if t in vocab.id2word else unk_index for t in latest_tokens]\n",
    "        # 获取所以隐藏层状态\n",
    "        hiddens = [h.hidden for h in hyps]\n",
    "\n",
    "        dec_input = tf.expand_dims(latest_tokens, axis=1)\n",
    "        dec_hidden = tf.stack(hiddens, axis=0)\n",
    "\n",
    "        # 单步运行decoder 计算需要的值\n",
    "        decoder_results = decoder_onestep(enc_output,\n",
    "                                          dec_input,\n",
    "                                          dec_hidden,\n",
    "                                          enc_extended_inp,\n",
    "                                          batch_oov_len)\n",
    "\n",
    "        # preds = decoder_results['final_dists']\n",
    "        # context_vector = decoder_results['last_context_vector']\n",
    "\n",
    "        dec_hidden = decoder_results['dec_hidden']\n",
    "        attention_weights = decoder_results['attention_weights']\n",
    "        top_k_log_probs = decoder_results['top_k_log_probs']\n",
    "        top_k_ids = decoder_results['top_k_ids']\n",
    "\n",
    "        # print('top_k_ids {}'.format(top_k_ids))\n",
    "\n",
    "        # 现阶段全部可能情况\n",
    "        all_hyps = []\n",
    "        # 原有的可能情况数量\n",
    "        num_orig_hyps = 1 if steps == 0 else len(hyps)\n",
    "\n",
    "        # 遍历添加所有可能结果\n",
    "        for i in range(num_orig_hyps):\n",
    "            h, new_hidden, attn_dist = hyps[i], dec_hidden[i], attention_weights[i]\n",
    "            # 分裂 添加 beam size 种可能性\n",
    "            for j in range(params['beam_size'] * 2):\n",
    "                # 构造可能的情况\n",
    "                new_hyp = h.extend(token=top_k_ids[i, j].numpy(),\n",
    "                                   log_prob=top_k_log_probs[i, j],\n",
    "                                   hidden=new_hidden,\n",
    "                                   attn_dist=attn_dist)\n",
    "                # 添加可能情况\n",
    "                all_hyps.append(new_hyp)\n",
    "\n",
    "        # 重置\n",
    "        hyps = []\n",
    "        # 按照概率来排序\n",
    "        sorted_hyps = sorted(all_hyps, key=lambda h: h.avg_log_prob, reverse=True)\n",
    "\n",
    "        # 筛选top前beam_size句话\n",
    "        for h in sorted_hyps:\n",
    "            if h.latest_token == stop_index:\n",
    "                # 长度符合预期,遇到句尾,添加到结果集\n",
    "                if steps >= params['min_dec_steps']:\n",
    "                    results.append(h)\n",
    "            else:\n",
    "                # 未到结束 ,添加到假设集\n",
    "                hyps.append(h)\n",
    "\n",
    "            # 如果假设句子正好等于beam_size 或者结果集正好等于beam_size 就不在添加\n",
    "            if len(hyps) == params['beam_size'] or len(results) == params['beam_size']:\n",
    "                break\n",
    "\n",
    "        steps += 1\n",
    "\n",
    "    if len(results) == 0:\n",
    "        results = hyps\n",
    "\n",
    "    hyps_sorted = sorted(results, key=lambda h: h.avg_log_prob, reverse=True)\n",
    "    best_hyp = hyps_sorted[0]\n",
    "    best_hyp.abstract = \" \".join([vocab.id_to_word(index) for index in best_hyp.tokens])\n",
    "    best_hyp.text = batch[0][\"article\"].numpy()[0].decode()\n",
    "    \n",
    "    return best_hyp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
